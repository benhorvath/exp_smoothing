---
title: "Exponential Smoothing"
author: "Simon U., Michael Y., Ben H.,  Sachid Deshmukh"
date: "March X, 2020"
output:
  ioslides_presentation: default
  beamer_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set()

# Helper to plot dummy time series models for illustration purposes
# x: Numeric vector
# x_hat: Numeric vector of forecast values
# ...: Commands to pass to plot
plot_forecast <- function(y, y_hat, ...) {
    n_y <- length(y)
    n_yhat <- length(y_hat)
    plot(1:(n_y+1), c(y, y_hat[1]), type='l', xlim=c(0, n_y+n_yhat), ylab='y, y_hat', xlab='t', ...)
    lines((n_y+1):(n_y+n_yhat-1), y_hat[2:n_yhat], type='l', col='red')
}
```

# What is exponential smoothing?

* Forecasting future observations 

* Using weighted averages of past observations
    
    - weights decay exponentially as observations recede further into the past

* Basic idea: More recent observations are more predictive than older points




# Exponential Smoothing Models

1. Naive---all weight is given to the last observation

2. Average---each past observation is given equal weight

3. Exponential weighted average---Recent observations get higher weight, older observations less weight

4. Holt linear---Same as 3, but accounts for time series with trend

5. Holt-Winters---Same as 4, but also accounts for time series with seasonality

6. State space---



# $ES_{1}$: Naive model

* The naive forecasting model can be thought of us exponential smoothing
* Where 100 percent of weight is given to the last observation:

```{r}
forecast_naive <- function(y, h) {
    n <- length(y)
    y_hat <- rep(y[n], h)
    return( y_hat )
}
```



# $ES_{1}$: Naive model: Example

```{r, fig.height=5}
y <- c(1, 4, 5, 2, 3, 6, 8)
y_hat <- forecast_naive(y, h=7)

plot_forecast(y, y_hat)
```

__Note__: No trend or seasonality!

# $ES_{2}$: Average model

* All future values are forecast as the average of the observed data
* Equivalent to exponential smoothing where each observation is given equal weight

```{r}
forecast_avg <- function(y, h) {
    y_hat <- rep(mean(y), h)
    return( y_hat )
}
```



# $ES_{2}$: Average model: Example

```{r, fig.height=5}
y_hat <- forecast_avg(y, h=7)
plot_forecast(y, y_hat)
```



# $ES_{3}$: Simple exponential smoothing

* More sophisticated models would given recent observations more weight, and decreasing weight for past observations
* Parameter $\alpha$ controls smoothing; can be optimized

$$\hat{y}_T = \alpha y_T + (1 - \alpha) \hat{y}_{T-1}$$

* $\hat{y}_T \equiv$ predicted value of $y$ at time $t$
* $\alpha \equiv$ user-chosen smoothing parameter, $0 \leq \alpha \leq 1$
    - Closer to 0 gives historical data more weight, closer to 1 gives recent data more weight
    - Often between $0.1--0.2$ is best
* $\hat{y}_{T-1} \equiv$ predicted value of $y$ at immediately previous period $t - 1$


# $ES_{3}$: Simple exponential smoothing: Smoothing parameter

where $y_t$ is the most recent observation:

| Observation | $\alpha = 0.2$ | $\alpha = 0.4$ | $\alpha = 0.6$ | $\alpha = 0.8$ |
|------------:|---------------:|---------------:|---------------:|---------------:|
|       $y_t$ |            0.2 |            0.4 |            0.6 |            0.8 |
|   $y_{t-1}$ |           0.16 |           0.24 |           0.26 |           0.16 |
|   $y_{t-2}$ |          0.128 |          0.144 |          0.096 |          0.032 |
|   $y_{t-3}$ |         0.1024 |         0.0864 |         0.0384 |         0.0064 |
|    $\vdots$ |       $\vdots$ |       $\vdots$ |       $\vdots$ |       $\vdots$ |



# $ES_{3}$: Simple exponential smoothing: Problem

__Problem__: What is $\hat{y}_{T-1}$ when $t = 1$?

$$\hat{y}_T = \alpha y_T + (1 - \alpha) \hat{y}_{T-1}$$



* Textbook: Component form, the level $\ell_0$

* Set for mean or median of the time series



# 

```{r}
forecast_simple <- function(y, h, alpha=0.1) {
    n <- length(y)
    l_0 <- mean(y)
    
    l <- c()
    for (i in 1:(n+1)) {
        if (i == 1) {
            l_i <- alpha * y[i] + (1 - alpha) * l_0
        } else {
            l_i <- alpha * y[i] + (1 - alpha) * l[i-1]
        }
        l <- append(l_i, l)
    }
    
    y_hat <- l[n+1]
    return( rep(y_hat, h) )
}
```

# $ES_{3}$: Simple exponential smoothing: Example

```{r}
y_hat <- forecast_simple(y, h=7, alpha=0.25)
plot_forecast(y, y_hat)
```


# $ES_{3}$: Weighted average: Optimizing $\alpha^*$

BEN: Not sure if we want to keep this??



# Interlude

* The previous method is effective for time series without trend or seasonality

* But what if your time series has trend?



# $ES_{4}$: Holt Linear Trend Model

Appropriate for time series that can be described with

$$y_t = \beta_0 + \beta_1 t + \epsilon_t$$

where $\beta_1$ quantifies the trend




# $ES_{4}$: Holt Linear Trend Model: Linear Time Series

* We can explicitly convert our previous time series to have trend using this formula:

```{r}
beta_0 <- 0
beta_1 <- 1.5
t_ <- 1:7
( y_1 <- beta_0 + y + beta_1*t_ )
```



# $ES_{4}$: Holt Linear Trend Model: Linear Time Series

```{r, echo=FALSE}
plot(t_, y, type='o', ylim=c(0, 20))
lines(t_, y_1, type='o', col='red')
arrows(x0=5, y0=4, x1 = 5, y1 = 9, length = 0.2, angle = 30, col='red', lty=2)
```


# $ES_{4}$: Holt Linear Trend Model:  Function/equations

TODO

# $ES_{4}$: Holt Linear Trend Model: Linear Time Series: Problem

__Problem__: What if you expect the trend to 'stabilize' over time?

Modify the above equations to use a _dampening_ coefficient $0 < \phi < 1$:






# Holt-Winters method + multiplicative + taxonomy







# ETS modeling (Innovations state space models)

* #### Exponential time smoothing method discussed so far are good for producing point forecast

* #### For all practical purposes point forecast is not enough and we need to produce distribution forecast e.g. quantiles

* #### Statistical methods like ETS state space models are good for genrating point forecast and distribution forecast

* ##### Statistical Forecasting Models - State Space Model
    + Generated same point forecast
    + Generates prediction intervals
        + Parameter Estimates, Error Estimates, Error bounds
        + PArametric modelling (distribution assumptions)

* ##### State Space model components
    + Measurement equation (observed)
    + State Equations (Unobserved- level, trend, seasonal)
    
* ##### Different state space models combinations
    + Additive and multiplicative errors
    + ETS (Error,Trend, Seasonal)

* ##### Examples
    + ETS(A,N,N) - Simple Exponential Smoothing with additive errors
    + ETS(M,N,N) - Simple Exponential Smoothing with multiplicative  errors
    + ETS(A,A,N) - Holt's linear method with additive errors
    + ETS(M,A,N) - Holt's linear method with multiplicative errors
        









# Conclusion

# Blah blah


